{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport PIL\nfrom skimage.feature import local_binary_pattern, greycomatrix, greycoprops\nfrom skimage.filters import gabor\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['train', 'test', 'train.csv', 'sample_submission.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport PIL\nfrom skimage.feature import local_binary_pattern, greycomatrix, greycoprops\nfrom skimage.filters import gabor\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nclass IMGFeatures:\n    def __init__(self):        \n        self.lbp_energy= 0\n        self.lbp_entropy = 0\n        self.contrast=0\n        self.dissimilarity=0\n        self.homogeneity=0\n        self.energy =0\n        self.correlation =0        \n        self.g_energy=0\n        self.g_entropy=0\n        \n    def load_image(self,path):\n        self.img = PIL.Image.open(path)\n        self.img_gray = self.img.convert('L') #Converting to grayscale\n        self.img_arr = np.array(self.img_gray) #Converting to array\n        #plt.imshow(self.img)\n    def calculate_features(self):\n        feat_lbp = local_binary_pattern(self.img_arr,8,1,'uniform') #Radius = 1, No. of neighbours = 8\n        feat_lbp = np.uint8((feat_lbp/feat_lbp.max())*255) #Converting to unit8\n        lbp_img = PIL.Image.fromarray(feat_lbp) #Conversion from array to PIL image\n        \n        \n        lbp_hist,_ = np.histogram(feat_lbp,8)\n        lbp_hist = np.array(lbp_hist,dtype=float)\n        lbp_prob = np.divide(lbp_hist,np.sum(lbp_hist))\n        self.lbp_energy = np.sum(lbp_prob**2)\n        self.lbp_entropy = -np.sum(np.multiply(lbp_prob,np.log2(lbp_prob)))\n        \n        gCoMat = greycomatrix(self.img_arr, [2], [0],256,symmetric=True, normed=True) # Co-occurance matrix\n        self.contrast = greycoprops(gCoMat, prop='contrast')\n        self.dissimilarity = greycoprops(gCoMat, prop='dissimilarity')\n        self.homogeneity = greycoprops(gCoMat, prop='homogeneity')\n        self.energy = greycoprops(gCoMat, prop='energy')\n        self.correlation = greycoprops(gCoMat, prop='correlation')\n        self.feat_glcm= np.array([self.contrast[0][0],self.dissimilarity[0][0],self.homogeneity[0][0],self.energy[0][0],self.correlation[0][0]])\n        # Gabor filter\n        gaborFilt_real,gaborFilt_imag = gabor(self.img_arr,frequency=0.6)\n        gaborFilt = (gaborFilt_real**2+gaborFilt_imag**2)//2\n                        \n        gabor_hist,_ = np.histogram(gaborFilt,8)\n        gabor_hist = np.array(gabor_hist,dtype=float)\n        gabor_prob = np.divide(gabor_hist,np.sum(gabor_hist))\n        self.g_energy = np.sum(gabor_prob**2)\n        self.g_entropy = -np.sum(np.multiply(gabor_prob,np.log2(gabor_prob)))\n        self.concat_feat = np.concatenate(([self.lbp_energy,self.lbp_entropy],self.feat_glcm,[self.g_energy,self.g_entropy]),axis=0)\n        ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6463a7baf600f5e62c31355747b94aa8d42a8620"
      },
      "cell_type": "code",
      "source": "train_df=pd.read_csv('../input/train.csv')\nprint(train_df[0:5].Id)\ntrain_df=train_df[0:5000]\nprint(train_df.shape)\n#we treat this like unet arquitect and like a mask we replace target to 0 to 27 outputs from 0 to 1 values\nNUM_CLASSES=28\ny_df=[[int(i) for i in s.split()] for s in train_df['Target']]\ny_df_final=np.zeros((train_df.shape[0],NUM_CLASSES)).astype(int)\n\nfor i,x in enumerate(y_df):\n    for val in x:\n        #print(x,val,i)    \n        y_df_final[i,val]=1\nprint(y_df_final[1])   \nprint(y_df_final.shape)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0    00070df0-bbc3-11e8-b2bc-ac1f6b6435d0\n1    000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0\n2    000a9596-bbc4-11e8-b2bc-ac1f6b6435d0\n3    000c99ba-bba4-11e8-b2b9-ac1f6b6435d0\n4    001838f8-bbca-11e8-b2bc-ac1f6b6435d0\nName: Id, dtype: object\n(5000, 2)\n[1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n(5000, 28)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b01aa71cc43377dde3008f81537c85c997aefb8"
      },
      "cell_type": "code",
      "source": "#one demo features\nIMG=IMGFeatures()\nfull_image_path='../input/train/'+train_df.values[0][0]+\"_green.png\"\nIMG.load_image(full_image_path)\nIMG.calculate_features()\nprint(IMG.concat_feat)\n\n#calculate all features for training set and green images\nlabel = []\nfeatLength = 2+5+2\ntrainFeats = np.zeros((len(train_df),featLength)) #Feature vector of each image\nfor tr in range(len(train_df)):\n    #print(str(tr+1)+'/'+str(len(train_df)))\n    IMG=IMGFeatures()\n    full_image_path='../input/train/'+train_df.values[tr][0]+\"_green.png\"\n    IMG.load_image(full_image_path)\n    IMG.calculate_features()\n    trainFeats[tr,:] = IMG.concat_feat \n    \nprint(\"DONE\")",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/skimage/feature/texture.py:109: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  if np.issubdtype(image.dtype, np.float):\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "[3.89184524e-01 1.90975749e+00 2.29446297e+02 9.37285922e+00\n 2.53350515e-01 1.83076731e-01 2.19140414e-01 9.04467326e-01\n 3.64650388e-01]\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log2\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in multiply\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "DONE\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10b8997b92226fd474c13f352680abfc4f12c704"
      },
      "cell_type": "code",
      "source": "#repalce some nan columns with 0\nfinal=np.nan_to_num(trainFeats)\nxpd=pd.DataFrame(final)\nxpd.isnull()\nprint(xpd[xpd.isnull().any(axis=1)])\n\n# Normalizing the train features to the range [0,1]\ntrMaxs = np.max(final,axis=0) #Finding maximum along each column\ntrMins = np.amin(final,axis=0) #Finding maximum along each column\ntrMaxs_rep = np.tile(trMaxs,(len(train_df),1)) #Repeating the maximum value along the rows\ntrMins_rep = np.tile(trMins,(len(train_df),1)) #Repeating the minimum value along the rows\ntrainFeatsNorm = np.divide(final-trMins_rep,trMaxs_rep) #Element-wise division\n\nprint(trainFeatsNorm.shape)\nprint(trainFeatsNorm[0])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Empty DataFrame\nColumns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\nIndex: []\n(5000, 9)\n[0.20197185 0.65932252 0.04818324 0.1987817  0.2261949  0.17939274\n 0.18945008 0.67209592 0.14398139]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e12abfb590e6de9ba8b759efaa34bff2eb70ec4"
      },
      "cell_type": "code",
      "source": "trainFeatsRed = np.zeros((len(train_df),featLength)) #Feature vector of each image\nfor tr in range(len(train_df)):\n    #print(str(tr+1)+'/'+str(len(train_df)))\n    IMG=IMGFeatures()\n    full_image_path='../input/train/'+train_df.values[tr][0]+\"_red.png\"\n    IMG.load_image(full_image_path)\n    IMG.calculate_features()\n    trainFeatsRed[tr,:] = IMG.concat_feat \n    \nprint(\"DONE\")",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log2\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in multiply\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "DONE\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0b37985e575d57bba10ff9f3fd471e9db0f48287"
      },
      "cell_type": "code",
      "source": "#repalce some nan columns values with 0\nfinal=np.nan_to_num(trainFeatsRed)\nxpd=pd.DataFrame(final)\nxpd.isnull()\nprint(xpd[xpd.isnull().any(axis=1)])\n\n# Normalizing the train features to the range [0,1]\ntrMaxs = np.max(final,axis=0) #Finding maximum along each column\ntrMins = np.amin(final,axis=0) #Finding maximum along each column\ntrMaxs_rep = np.tile(trMaxs,(len(train_df),1)) #Repeating the maximum value along the rows\ntrMins_rep = np.tile(trMins,(len(train_df),1)) #Repeating the minimum value along the rows\ntrainFeatsNormR = np.divide(final-trMins_rep,trMaxs_rep) #Element-wise division\n\nprint(trainFeatsNormR.shape)\nprint(trainFeatsNormR[0])",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Empty DataFrame\nColumns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\nIndex: []\n(5000, 9)\n[0.17078801 0.69338936 0.03752456 0.16158449 0.22302551 0.18667127\n 0.17738475 0.66667844 0.20679227]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9fd986aa962c66606741ee03b45ed924ac3a306e"
      },
      "cell_type": "code",
      "source": "trainFeatsBlue = np.zeros((len(train_df),featLength)) #Feature vector of each image\nfor tr in range(len(train_df)):\n    #print(str(tr+1)+'/'+str(len(train_df)))\n    IMG=IMGFeatures()\n    full_image_path='../input/train/'+train_df.values[tr][0]+\"_blue.png\"\n    IMG.load_image(full_image_path)\n    IMG.calculate_features()\n    trainFeatsBlue[tr,:] = IMG.concat_feat \n    \nprint(\"DONE\")\n\n#repalce some nan columns values with 0\nfinal=np.nan_to_num(trainFeatsBlue)\nxpd=pd.DataFrame(final)\nxpd.isnull()\nprint(xpd[xpd.isnull().any(axis=1)])\n\n# Normalizing the train features to the range [0,1]\ntrMaxs = np.max(final,axis=0) #Finding maximum along each column\ntrMins = np.amin(final,axis=0) #Finding maximum along each column\ntrMaxs_rep = np.tile(trMaxs,(len(train_df),1)) #Repeating the maximum value along the rows\ntrMins_rep = np.tile(trMins,(len(train_df),1)) #Repeating the minimum value along the rows\ntrainFeatsNormB = np.divide(final-trMins_rep,trMaxs_rep) #Element-wise division\n\nprint(trainFeatsNormB.shape)\nprint(trainFeatsNormB[0])",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log2\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in multiply\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: divide by zero encountered in log2\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in multiply\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "DONE\nEmpty DataFrame\nColumns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\nIndex: []\n(5000, 9)\n[0.25532122 0.6610356  0.01762039 0.12401083 0.31776137 0.41269838\n 0.55388748 0.5315787  0.03338543]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3edf8698f8765b28b1778b379b508c2129e1249d"
      },
      "cell_type": "code",
      "source": "##join trainFeatsNorm and trainFeatsNormR adn trainFeatsNormB (green and red and blue)\nallfeats=np.concatenate((trainFeatsNorm,trainFeatsNormR,trainFeatsNormB),axis=-1)\nprint(allfeats.shape) #neet to be [size,18]",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(5000, 27)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e5ffaa36ceea9ad591d1bc2a0e975852c256f69"
      },
      "cell_type": "code",
      "source": "##join trainFeatsNorm and trainFeatsNormR adn trainFeatsNormB (green and red and blue)\nlista=[]\nlista.append(trainFeatsNorm)\nlista.append(trainFeatsNormR)\nlista.append(trainFeatsNormB)\nallconvfeat=np.array(lista)\nallconvfeat=allconvfeat.reshape(allconvfeat.shape[1],allconvfeat.shape[2],allconvfeat.shape[0])\n#allconvfeat=np.concatenate((trainFeatsNorm,trainFeatsNormR,trainFeatsNormB),axis=2)\nprint(allconvfeat.shape) #neet to be [size,18]",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(5000, 9, 3)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41ad7dfe8afa65dd2ef1272f0063ff11ee86938f"
      },
      "cell_type": "code",
      "source": "#we have 9 features now we tran to train a simple classifcator and check how good are this features, Â¿can imporve our CNN model?\nimport keras\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense,Convolution1D,Flatten,Activation,Dropout,MaxPooling2D,Conv2D,Input\nfrom keras import backend as K\nimport tensorflow as tf\ndef f1_loss(y_true, y_pred):\n    \n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return 1 - K.mean(f1)\n\ndef bce_f1_loss(y_true, y_pred):    \n    return K.binary_crossentropy(y_true,y_pred)+f1_loss(y_true,y_pred)\n\ndef create_dense_baseline():    \n    # create model\n    model = Sequential()\n    model.add(Dense(100, input_dim=allfeats.shape[1], kernel_initializer='normal', activation='relu'))\n    model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(100, kernel_initializer='normal', activation='relu'))\n    #model.add(Dense(NUM_CLASSES, kernel_initializer='normal', activation='sigmoid'))\n    # Compile model\n    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','binary_crossentropy',f1_loss,bce_f1_loss])\n    return model\n\ndef create_conv_baseline():    \n    # create model\n    model = Sequential()\n    model.add(Convolution1D(nb_filter=32, filter_length=1, input_shape=(allfeats.shape[1], 1)))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(2048, activation='relu'))\n    model.add(Dense(1024, activation='relu'))\n    #model.add(Dense(NUM_CLASSES, kernel_initializer='normal', activation='sigmoid'))\n    # Compile model\n    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','binary_crossentropy',f1_loss,bce_f1_loss])\n    return model\n\ndef part1():\n    \n    minput=Input(shape=(allconvfeat.shape[1], allconvfeat.shape[2]))\n    x=Convolution1D(nb_filter=32, filter_length=1, input_shape=(allfeats.shape[1], 1))(minput)\n    x=Activation('relu')(x)\n    x=Flatten()(x)\n    \n    return minput,x\n\n\ndef part2():\n    minput=Input(shape=(27,))\n    x=Dense(100)(minput)\n    x=Activation('relu')(x)\n    x=Dropout(0.5)(x)    \n    x=Dense(100)(x)\n    x=Activation('relu')(x)\n    x=Dropout(0.5)(x)\n    x=Dense(100)(x)\n    x=Activation('relu')(x)\n    x=Dropout(0.5)(x)\n    \n    return minput,x\n\ndef part3():\n    minput=Input(shape=(512,512,3))\n    x=Conv2D(32,(3,3))(minput)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n    x=Conv2D(32,(3,3))(x)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n    x=Conv2D(64,(3,3))(x)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n    x=Conv2D(64,(3,3))(x)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n    x=Conv2D(128,(3,3))(x)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n    x=Conv2D(128,(3,3))(x)\n    x=Activation('relu')(x)\n    x=MaxPooling2D(pool_size=(2, 2))(x)\n\n    x=Flatten()(x)\n    return minput,x\n# the model so far outputs 3D feature maps (height, width, features)\n\n\n\n\n\nInput1,model1=part1()\nInput2,model2=part2()\nInput3,model3=part3()\nx = keras.layers.concatenate([ model2,model3])\n# We stack a deep densely-connected network on top\nx = Dense(1024, activation='relu')(x)\nx = Dense(1024, activation='relu')(x)\nx = Dense(1024, activation='relu')(x)\nmain_output = Dense(NUM_CLASSES, activation='sigmoid', name='main_output')(x)\nmodel = Model(inputs=[ Input2,Input3], outputs=main_output)\nmodel.summary()\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','binary_crossentropy',f1_loss,bce_f1_loss])\n#model.add(Dense(28))\n#model.add(Activation('sigmoid'))\n#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','binary_crossentropy',f1_loss,bce_f1_loss])\n#model=create_baseline()\n\n",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(27, 1), filters=32, kernel_size=1)`\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_9 (InputLayer)            (None, 512, 512, 3)  0                                            \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 510, 510, 32) 896         input_9[0][0]                    \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 510, 510, 32) 0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_13 (MaxPooling2D) (None, 255, 255, 32) 0           activation_25[0][0]              \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 253, 253, 32) 9248        max_pooling2d_13[0][0]           \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 253, 253, 32) 0           conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_14 (MaxPooling2D) (None, 126, 126, 32) 0           activation_26[0][0]              \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 124, 124, 64) 18496       max_pooling2d_14[0][0]           \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 124, 124, 64) 0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_15 (MaxPooling2D) (None, 62, 62, 64)   0           activation_27[0][0]              \n__________________________________________________________________________________________________\ninput_8 (InputLayer)            (None, 27)           0                                            \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 60, 60, 64)   36928       max_pooling2d_15[0][0]           \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 100)          2800        input_8[0][0]                    \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 60, 60, 64)   0           conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 100)          0           dense_13[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_16 (MaxPooling2D) (None, 30, 30, 64)   0           activation_28[0][0]              \n__________________________________________________________________________________________________\ndropout_7 (Dropout)             (None, 100)          0           activation_22[0][0]              \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 28, 28, 128)  73856       max_pooling2d_16[0][0]           \n__________________________________________________________________________________________________\ndense_14 (Dense)                (None, 100)          10100       dropout_7[0][0]                  \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 28, 28, 128)  0           conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 100)          0           dense_14[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_17 (MaxPooling2D) (None, 14, 14, 128)  0           activation_29[0][0]              \n__________________________________________________________________________________________________\ndropout_8 (Dropout)             (None, 100)          0           activation_23[0][0]              \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 12, 12, 128)  147584      max_pooling2d_17[0][0]           \n__________________________________________________________________________________________________\ndense_15 (Dense)                (None, 100)          10100       dropout_8[0][0]                  \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 12, 12, 128)  0           conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 100)          0           dense_15[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_18 (MaxPooling2D) (None, 6, 6, 128)    0           activation_30[0][0]              \n__________________________________________________________________________________________________\ndropout_9 (Dropout)             (None, 100)          0           activation_24[0][0]              \n__________________________________________________________________________________________________\nflatten_6 (Flatten)             (None, 4608)         0           max_pooling2d_18[0][0]           \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 4708)         0           dropout_9[0][0]                  \n                                                                 flatten_6[0][0]                  \n__________________________________________________________________________________________________\ndense_16 (Dense)                (None, 1024)         4822016     concatenate_3[0][0]              \n__________________________________________________________________________________________________\ndense_17 (Dense)                (None, 1024)         1049600     dense_16[0][0]                   \n__________________________________________________________________________________________________\ndense_18 (Dense)                (None, 1024)         1049600     dense_17[0][0]                   \n__________________________________________________________________________________________________\nmain_output (Dense)             (None, 28)           28700       dense_18[0][0]                   \n==================================================================================================\nTotal params: 7,259,924\nTrainable params: 7,259,924\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "571524b9939f3e24d0cc7c0715fe29d320a5df8b"
      },
      "cell_type": "code",
      "source": "print(allfeats.shape)\n#allconvfeat=allfeats.reshape(-1,allfeats.shape[1],1)\nprint(allconvfeat.shape)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(5000, 27)\n(5000, 9, 3)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1eb0406bcb46fa5a3d5ce60764d6cc60cb59111"
      },
      "cell_type": "code",
      "source": "from keras import backend\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Conv2DTranspose,Convolution2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.callbacks import EarlyStopping, TensorBoard\n\n",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", name=\"Conv0\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), name=\"MaxPool0\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", name=\"Conv1\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), name=\"MaxPool1\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", name=\"Conv2\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((2, 2), name=\"MaxPool2\", padding=\"same\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", name=\"Deconv0\", padding=\"same\")`\n",
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 is incompatible with layer Deconv0: expected axis -1 of input shape to have value 8 but got shape (None, 8, 64.0, 64.0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1e8117ec74d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mautoclas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConvolutionalAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mautoclas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-1e8117ec74d0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, h_in, w_in, dims)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mconvlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Deconv{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mupsample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UpSampling{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                 \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' of input shape to have '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                                 \u001b[0;34m'value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                                 ' but got shape ' + str(x_shape))\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer Deconv0: expected axis -1 of input shape to have value 8 but got shape (None, 8, 64.0, 64.0)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c341fdc4a971271228252887241f0bb731c732a"
      },
      "cell_type": "code",
      "source": "\n#tenemos las features, ahora vamos a entrenar un autoencode para reducir las dimensiones\n\n   #net = lays.conv2d(inputs, 32, [5, 5], stride=2, padding='SAME')\n    #net = lays.conv2d(net, 16, [5, 5], stride=2, padding='SAME')\n    #net = lays.conv2d(net, 8, [5, 5], stride=4, padding='SAME')\n    # decoder\n    # 2 x 2 x 8    ->  8 x 8 x 16\n    # 8 x 8 x 16   ->  16 x 16 x 32\n    # 16 x 16 x 32  ->  32 x 32 x 1\n    #net = lays.conv2d_transpose(net, 16, [5, 5], stride=4, padding='SAME')\n    #net = lays.conv2d_transpose(net, 32, [5, 5], stride=2, padding='SAME')\n    #net = lays.conv2d_transpose(net, 1, [5, 5], stride=2, padding='SAME', activation_fn=tf.nn.tanh)\n    \n#input_img = Input(shape=(512, 512, 3))  # adapt this if using `channels_first` image data format\n#x=Conv2D(32,(5,5),strides=2,padding='same',activation=\"relu\")(input_img)\n#x=Conv2D(16,(5,5),strides=2,padding='same',activation=\"relu\")(x)\n#x=Conv2D(8,(5,5),strides=4,padding='same',name=\"encoded\",activation=\"relu\")(x)\n#x=Conv2DTranspose(16,(5,5),strides=4,padding='same',activation=\"relu\")(x)\n#x=Conv2DTranspose(32,(5,5),strides=2,padding='same',activation=\"relu\")(x)\n#x=Conv2DTranspose(3,(5,5),strides=2,padding='same',activation=\"sigmoid\")(x)\n\n#autoencoder = Model(input_img, x)\nimg_size_target=284\ninput_img = Input(shape=(img_size_target, img_size_target, 3))  # adapt this if using `channels_first` image data format\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nautoencoder.summary()\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\nfrom skimage.transform import resize\nfrom skimage import util \n\ndef downsample(img):# not used\n    \n    if img_size_target==512:\n        return img\n    else:\n        return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    \ndef data_generator_ae(traind_df,batch_size):\n    while True:        \n        random_indexes = np.random.choice(len(traind_df), batch_size)        \n        batch_images = np.empty((batch_size, img_size_target, img_size_target, 3))\n        \n        for x in range(batch_size):            \n            for i, idx in enumerate(random_indexes):\n              #  name=\"sdasd\"                \n                #name=\"../input/train/{}_green.png\".format(np.squeeze(traind_df[idx]))\n                name=\"../input/train/{}_red.png\".format(traind_df.values[idx][0])\n                R=(downsample(np.array(load_img(name, grayscale=True))) / 1)-0                \n                name=\"../input/train/{}_green.png\".format(traind_df.values[idx][0])\n                G=(downsample(np.array(load_img(name, grayscale=True))) / 1)-0\n                name=\"../input/train/{}_blue.png\".format(traind_df.values[idx][0])\n                B=(downsample(np.array(load_img(name, grayscale=True))) / 1)-0\n                image=np.concatenate((R.reshape(img_size_target,img_size_target,1),G.reshape(img_size_target,img_size_target,1),B.reshape(img_size_target,img_size_target,1)),axis=2)\n                batch_images[i] = util.invert((image/255))\n                \n        yield batch_images,batch_images\n    \nret,_=next(data_generator_ae(train_df,1))   \nprint(ret[0].shape)                   \n\n",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_54 (InputLayer)        (None, 284, 284, 3)       0         \n_________________________________________________________________\nconv2d_245 (Conv2D)          (None, 284, 284, 16)      448       \n_________________________________________________________________\nmax_pooling2d_93 (MaxPooling (None, 142, 142, 16)      0         \n_________________________________________________________________\nconv2d_246 (Conv2D)          (None, 142, 142, 8)       1160      \n_________________________________________________________________\nmax_pooling2d_94 (MaxPooling (None, 71, 71, 8)         0         \n_________________________________________________________________\nconv2d_247 (Conv2D)          (None, 71, 71, 8)         584       \n_________________________________________________________________\nmax_pooling2d_95 (MaxPooling (None, 36, 36, 8)         0         \n_________________________________________________________________\nconv2d_248 (Conv2D)          (None, 36, 36, 8)         584       \n_________________________________________________________________\nup_sampling2d_85 (UpSampling (None, 72, 72, 8)         0         \n_________________________________________________________________\nconv2d_249 (Conv2D)          (None, 72, 72, 8)         584       \n_________________________________________________________________\nup_sampling2d_86 (UpSampling (None, 144, 144, 8)       0         \n_________________________________________________________________\nconv2d_250 (Conv2D)          (None, 142, 142, 16)      1168      \n_________________________________________________________________\nup_sampling2d_87 (UpSampling (None, 284, 284, 16)      0         \n_________________________________________________________________\nconv2d_251 (Conv2D)          (None, 284, 284, 3)       435       \n=================================================================\nTotal params: 4,963\nTrainable params: 4,963\nNon-trainable params: 0\n_________________________________________________________________\n(284, 284, 3)\nEpoch 1/10\n10/10 [==============================] - 34s 3s/step - loss: 0.4733\nEpoch 2/10\n10/10 [==============================] - 31s 3s/step - loss: 0.2693\nEpoch 3/10\n10/10 [==============================] - 30s 3s/step - loss: 0.2311\nEpoch 4/10\n10/10 [==============================] - 31s 3s/step - loss: 0.2355\nEpoch 5/10\n10/10 [==============================] - 30s 3s/step - loss: 0.2331\nEpoch 6/10\n10/10 [==============================] - 31s 3s/step - loss: 0.2487\nEpoch 7/10\n10/10 [==============================] - 32s 3s/step - loss: 0.2299\nEpoch 8/10\n10/10 [==============================] - 30s 3s/step - loss: 0.2399\nEpoch 9/10\n10/10 [==============================] - 30s 3s/step - loss: 0.2322\nEpoch 10/10\n10/10 [==============================] - 31s 3s/step - loss: 0.2579\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 98,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fcee86d5828>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df649a4cd5df22e1f1ae921b1e14597d6cf237e5"
      },
      "cell_type": "code",
      "source": "autoencoder.fit_generator(data_generator_ae(train_df,10),steps_per_epoch=10,epochs=10,verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29e6a14befa9085efa84fcceac193d4c1688e06a"
      },
      "cell_type": "code",
      "source": "ret,_=next(data_generator_ae(train_df,1))   \nprint(ret[0].shape) \nplt.imshow((ret[0]))\nplt.show()\nrecon=autoencoder.predict(ret)\nplt.imshow((recon[0]))\nplt.show()",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(284, 284, 3)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66831cc6318a736e07150d0c7e0f4c8ef2a4b653"
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n\ndef data_generator(allconvfeat,allfeats,traind_df,y_labels,batch_size):\n    while True:        \n        random_indexes = np.random.choice(len(traind_df), batch_size)\n        batch_conv = np.empty((batch_size, allconvfeat.shape[1], allconvfeat.shape[2]))\n        batch_dense = np.empty((batch_size, 27))\n        batch_images = np.empty((batch_size, 512, 512, 3))\n        batch_labels = np.zeros((batch_size, 28))\n        for x in range(batch_size):            \n            for i, idx in enumerate(random_indexes):\n              #  name=\"sdasd\"                \n                #name=\"../input/train/{}_green.png\".format(np.squeeze(traind_df[idx]))\n                name=\"../input/train/{}_red.png\".format(traind_df.values[idx][0])\n                R=np.array(load_img(name, grayscale=True)) / 255                \n                name=\"../input/train/{}_green.png\".format(traind_df.values[idx][0])\n                G=np.array(load_img(name, grayscale=True)) / 255\n                name=\"../input/train/{}_blue.png\".format(traind_df.values[idx][0])\n                B=np.array(load_img(name, grayscale=True)) / 255\n                image=np.concatenate((R.reshape(512,512,1),G.reshape(512,512,1),B.reshape(512,512,1)),axis=2)\n                batch_images[i] = image\n                batch_labels[i]=y_labels[idx]\n                batch_conv[i]=allconvfeat[idx]\n                batch_dense[i]=allfeats[idx]\n        yield [batch_dense,batch_images],batch_labels\n    \nret,_=next(data_generator(allconvfeat,allfeats,train_df,y_df_final,1))   \nprint(ret[0].shape)                   ",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(1, 27)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c52c7ad1f699cf0254dd09bf79d2a907a668358"
      },
      "cell_type": "code",
      "source": "model.fit_generator(data_generator(allconvfeat,allfeats,train_df,y_df_final,10),steps_per_epoch=50,epochs=10,verbose=1)",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n50/50 [==============================] - 83s 2s/step - loss: 0.2417 - acc: 0.9288 - binary_crossentropy: 0.2417 - f1_loss: 0.9551 - bce_f1_loss: 1.1967\nEpoch 2/10\n50/50 [==============================] - 81s 2s/step - loss: 0.1816 - acc: 0.9409 - binary_crossentropy: 0.1816 - f1_loss: 0.9549 - bce_f1_loss: 1.1365\nEpoch 3/10\n50/50 [==============================] - 82s 2s/step - loss: 0.1820 - acc: 0.9421 - binary_crossentropy: 0.1820 - f1_loss: 0.9576 - bce_f1_loss: 1.1395\nEpoch 4/10\n50/50 [==============================] - 82s 2s/step - loss: 0.1812 - acc: 0.9409 - binary_crossentropy: 0.1812 - f1_loss: 0.9567 - bce_f1_loss: 1.1379\nEpoch 5/10\n50/50 [==============================] - 81s 2s/step - loss: 0.1805 - acc: 0.9405 - binary_crossentropy: 0.1805 - f1_loss: 0.9558 - bce_f1_loss: 1.1362\nEpoch 6/10\n50/50 [==============================] - 81s 2s/step - loss: 0.1786 - acc: 0.9394 - binary_crossentropy: 0.1786 - f1_loss: 0.9548 - bce_f1_loss: 1.1333\nEpoch 7/10\n50/50 [==============================] - 83s 2s/step - loss: 0.1773 - acc: 0.9381 - binary_crossentropy: 0.1773 - f1_loss: 0.9547 - bce_f1_loss: 1.1320\nEpoch 8/10\n50/50 [==============================] - 82s 2s/step - loss: 0.1822 - acc: 0.9401 - binary_crossentropy: 0.1822 - f1_loss: 0.9555 - bce_f1_loss: 1.1377\nEpoch 9/10\n50/50 [==============================] - 83s 2s/step - loss: 0.1779 - acc: 0.9412 - binary_crossentropy: 0.1779 - f1_loss: 0.9565 - bce_f1_loss: 1.1344\nEpoch 10/10\n50/50 [==============================] - 84s 2s/step - loss: 0.1738 - acc: 0.9399 - binary_crossentropy: 0.1738 - f1_loss: 0.9554 - bce_f1_loss: 1.1291\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fcf4c48b160>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b07f5307072a235bc52a365843215c5e2d070c91"
      },
      "cell_type": "code",
      "source": "#model.fit([allconvfeat,allfeats],y_df_final,batch_size=320,epochs=300,validation_split=0.1,verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "efe4561d201d1d9357c4caa4b3e30537e53fbe97"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "45012d27c9c7e959326867d2078801e6842e6929"
      },
      "cell_type": "code",
      "source": "model.fit(allconvfeat,y_df_final,batch_size=320,epochs=300,validation_split=0.1,verbose=1)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}