{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#we need prepoces all image at once to get max and min to normalize them\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport PIL\nfrom skimage.feature import local_binary_pattern, greycomatrix, greycoprops\nfrom skimage.filters import gabor\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import gaussian_filter\nfrom scipy.stats import kurtosis, skew\nfrom scipy.ndimage import laplace, sobel\nfrom skimage import img_as_float\nfrom skimage.morphology import reconstruction\n\nclass IMGFeatures:\n    def __init__(self):        \n        self.lbp_energy= 0\n        self.lbp_entropy = 0\n        self.contrast=0\n        self.dissimilarity=0\n        self.homogeneity=0\n        self.energy =0\n        self.correlation =0        \n        self.g_energy=0\n        self.g_entropy=0\n\n# Isolation function.\n    def iso(self,arr):\n        image = img_as_float(arr.reshape(arr.shape[0],arr.shape[1]))\n        image = gaussian_filter(image,2.5)\n        seed = np.copy(image)\n        seed[1:-1, 1:-1] = image.min()\n        mask = image \n        dilated = reconstruction(seed, mask, method='dilation')\n        return image-dilated\n\n    # Standard deviation for sobel filter\n    def sobelstd(self,arr, axis=0):\n        image = img_as_float(arr.reshape(arr.shape[0],arr.shape[1]))\n        sobelstd = sobel(image, axis=axis, mode='reflect', cval=0.0).ravel()\n        return [sobelstd.std(), sobelstd.max(), sobelstd.mean()]\n\n    # Standard deviation for laplace filter\n    def lapacestd(self,arr):\n        image = img_as_float(arr.reshape(arr.shape[0],arr.shape[1]))\n        lapacestd = laplace(image, mode='reflect', cval=0.0).ravel()\n        return [lapacestd.std(), lapacestd.max(), lapacestd.mean()]\n\n    def volume(self,arr):\n        return np.sum(arr)\n    \n    def load_image(self,path):\n        self.img = PIL.Image.open(path)\n        self.img_gray = self.img.convert('L') #Converting to grayscale\n        self.img_arr = np.array(self.img_gray) #Converting to array\n        #plt.imshow(self.img)\n    def calculate_features(self):\n        \n        feat_lbp = local_binary_pattern(self.img_arr,8,1,'uniform') #Radius = 1, No. of neighbours = 8\n        feat_lbp = np.uint8((feat_lbp/feat_lbp.max())*255) #Converting to unit8\n        \n        lbp_img = PIL.Image.fromarray(feat_lbp) #Conversion from array to PIL image\n        \n        \n        lbp_hist,_ = np.histogram(feat_lbp,8)\n        lbp_hist = np.array(lbp_hist,dtype=float)\n        lbp_prob = np.divide(lbp_hist,np.sum(lbp_hist))\n        self.lbp_energy = np.sum(lbp_prob**2)\n        self.lbp_entropy = -np.sum(np.multiply(lbp_prob,np.log2(lbp_prob)))\n        \n        gCoMat = greycomatrix(self.img_arr, [2], [0],256,symmetric=True, normed=True) # Co-occurance matrix\n        self.contrast = greycoprops(gCoMat, prop='contrast')\n        self.dissimilarity = greycoprops(gCoMat, prop='dissimilarity')\n        self.homogeneity = greycoprops(gCoMat, prop='homogeneity')\n        self.energy = greycoprops(gCoMat, prop='energy')\n        self.correlation = greycoprops(gCoMat, prop='correlation')\n        self.feat_glcm= np.array([self.contrast[0][0],self.dissimilarity[0][0],self.homogeneity[0][0],self.energy[0][0],self.correlation[0][0]])\n        # Gabor filter\n        gaborFilt_real,gaborFilt_imag = gabor(self.img_arr,frequency=0.6)\n        gaborFilt = (gaborFilt_real**2+gaborFilt_imag**2)//2\n                        \n        gabor_hist,_ = np.histogram(gaborFilt,8)\n        gabor_hist = np.array(gabor_hist,dtype=float)\n        gabor_prob = np.divide(gabor_hist,np.sum(gabor_hist))\n        self.g_energy = np.sum(gabor_prob**2)\n        self.g_entropy = -np.sum(np.multiply(gabor_prob,np.log2(gabor_prob)))\n        \n        self.concat_feat = np.concatenate(([self.lbp_energy,self.lbp_entropy],self.feat_glcm,[self.g_energy,self.g_entropy],self.sobelstd(self.img_arr),self.lapacestd(self.img_arr)),axis=0)\nprint(\"DONE\")        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a3bf60e636f3303c348898d8b5362c78e6c3c09"},"cell_type":"code","source":"#we have 8 ending files \n#---->4 files with feaures calculated no normalitzation one for all image (train and test)\n\ntrain_df=pd.read_csv('../input/train.csv')\nprint(train_df[0:5].Id)\n#train_df=train_df[0:5]\nprint(train_df.shape)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6de8d18c9c2eb190445bb6b73ae2d33382bef2c6"},"cell_type":"code","source":"type(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c5cd149614ac8bb3246425bf4d409cec1f37814"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6ab62bfb07e8f43d7bf930254613f838fda8096"},"cell_type":"code","source":"#calculate all features for training set and green images\nlabel = []\n#trainFeats = np.zeros((len(train_df),featLength)) #Feature vector of each image\ncolnames=(\"name\",\"lbp_energy\",\"lbp_entropy\",\"contrast\",\"dissimilarity\",\"homogeneity\",\"energy\",\"correlation\",\"g_energy\",\"g_entropy\",\"so_std\",\"so_max\",\"so_mean\",\"la_std\",\"la_max\",\"la_mean\")\nallFeats=pd.DataFrame(columns=colnames)\nallFeats\n\nchanels=[\"_red.png\",\"_green.png\",\"_blue.png\",\"_yellow.png\"]\n\nfor tr in range(len(train_df)):    \n    for x in range((len(chanels))):\n        IMG=IMGFeatures()\n        full_image_path='../input/train/'+train_df.values[tr][0]+chanels[x]        \n        IMG.load_image(full_image_path)\n        IMG.calculate_features()\n        #print(IMG.concat_feat[0])\n        df2 = pd.DataFrame([[full_image_path,IMG.concat_feat[0],IMG.concat_feat[1],IMG.concat_feat[2],IMG.concat_feat[3],IMG.concat_feat[4],IMG.concat_feat[5],\n                             IMG.concat_feat[6],IMG.concat_feat[7],IMG.concat_feat[8],IMG.concat_feat[9],IMG.concat_feat[10],IMG.concat_feat[11],IMG.concat_feat[12]\n                            ,IMG.concat_feat[13],IMG.concat_feat[14]]],columns=colnames)\n      \n        allFeats=allFeats.append(df2)      \n        del IMG\nprint(\"DONE\")\nlen(allFeats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"16c97d90199fdd07ccaa59b7b79f102070abef2c"},"cell_type":"code","source":"#now we fill in all feats for test data\nfrom os import listdir\nfrom os.path import isfile, join\nmypath=\"../input/test/\"\nonlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n#onlyfiles=onlyfiles[0:5]\nfor tr in range(len(train_df)):        \n    IMG=IMGFeatures()\n    full_image_path=mypath+onlyfiles[tr]\n    IMG.load_image(full_image_path)\n    IMG.calculate_features()\n    #print(IMG.concat_feat[0])\n    df2 = pd.DataFrame([[full_image_path,IMG.concat_feat[0],IMG.concat_feat[1],IMG.concat_feat[2],IMG.concat_feat[3],IMG.concat_feat[4],IMG.concat_feat[5],\n                         IMG.concat_feat[6],IMG.concat_feat[7],IMG.concat_feat[8],IMG.concat_feat[9],IMG.concat_feat[10],IMG.concat_feat[11],IMG.concat_feat[12]\n                        ,IMG.concat_feat[13],IMG.concat_feat[14]]],columns=colnames)\n\n    allFeats=allFeats.append(df2)      \n    del IMG\nallFeats        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce276480f9f8d76f3d0d5062baefdf8daf1d46a5"},"cell_type":"code","source":"allFeats.to_csv(\"allfeats.csv\",index=False)\nprint(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72c8f8bf153798ec0dfcbbd212074530184c20c3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}